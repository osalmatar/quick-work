{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = pd.read_csv('ATR.csv')\n",
    "B = pd.read_csv('D_EW_B.csv')\n",
    "C = pd.read_csv('D_EW_S.csv')\n",
    "D = pd.read_csv('HHLL.csv')\n",
    "E = pd.read_csv('LR_Explore.csv')\n",
    "F = pd.read_csv('Pattern_Revv.csv')\n",
    "G = pd.read_csv('SCTR_Trial.csv')\n",
    "H = pd.read_csv('ZigZag.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data cleaning to rename each value of Buy into the name of the tinker instead of 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of           Ticker  Date/Time Buy_ATR\n",
       "0      360ONE.NS  9/26/2024     ATR\n",
       "1      1STCUS.BO  9/24/2024     ATR\n",
       "2       ^CNXAUTO  9/26/2024     ATR\n",
       "3    ^CNXPSUBANK  9/23/2024     ATR\n",
       "4      ^CNXMETAL  9/24/2024     ATR\n",
       "..           ...        ...     ...\n",
       "400  ZBINTXPP.BO  9/27/2024     ATR\n",
       "401  ZEEMEDIA.NS  9/23/2024     ATR\n",
       "402  ZEEMEDIA.NS  9/26/2024     ATR\n",
       "403  ZSARACOM.BO  9/27/2024     ATR\n",
       "404     ZUARI.NS  9/27/2024     ATR\n",
       "\n",
       "[405 rows x 3 columns]>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ensure Date/Time is properly parsed as datetime\n",
    "for df in [A, B, C, D, E, F, G, H]:\n",
    "    df['Date/Time'] = pd.to_datetime(df['Date/Time'], errors='coerce')  # Convert to datetime and handle errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['EW'], dtype=object)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Renaming columns and performing necessary transformations\n",
    "A.rename(columns={'Buy': 'Buy_ATR'}, inplace=True)\n",
    "A['Buy_ATR'] = A['Buy_ATR'].replace(1, 'ATR')\n",
    "\n",
    "B.rename(columns={'Mega Buy by Larger Wave ': 'Buy_EW'}, inplace=True)\n",
    "B['Buy_EW'] = 'EW'\n",
    "\n",
    "E.rename(columns={'myBuy ': 'Buy_LR'}, inplace=True)\n",
    "E['Buy_LR'] = E['Buy_LR'].replace(1, 'LR')\n",
    "\n",
    "F.rename(columns={'BullBreak': 'Buy_BB'}, inplace=True)\n",
    "F['Buy_BB'] = F['Buy_BB'].replace('bullish Breakout', 'BB')\n",
    "\n",
    "H.rename(columns={'Buy':'Buy_ZZ'}, inplace=True)\n",
    "H['Buy_ZZ'] = H['Buy_ZZ'].replace(1, 'ZZ')\n",
    "\n",
    "# Map values in the 'Pattern' column to new values\n",
    "pattern_mapping = {\n",
    "    'Up Channel': '_UC',\n",
    "    'Wedge': '_W',\n",
    "    'Down Channel': '_DC',\n",
    "    'Broadening Wedge': '_BW',\n",
    "    'Ascending Triangle': '_AT',\n",
    "    'Decending Triangle': '_DT'\n",
    "    }\n",
    "F['Pattern'] = F['Pattern'].replace(pattern_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of               Ticker  Date/Time  Close  Mega Sellby Larger Wave        SL\n",
       "0          360ONE.NS  7/31/2024   1068                  1128.16    926.30\n",
       "1          360ONE.NS  9/12/2024   1068                  1104.03   1054.50\n",
       "2      21STCENMGM.NS  7/16/2024    109                    81.10     47.65\n",
       "3      21STCENMGM.NS  9/11/2024    109                   140.01     74.35\n",
       "4          1STCUS.BO  8/13/2024    122                   127.15     84.20\n",
       "...              ...        ...    ...                      ...       ...\n",
       "14440      ZIMLAB.BO   9/2/2024    113                   122.70    109.45\n",
       "14441    ZSARACOM.BO  7/12/2024  23827                  9474.80   8799.20\n",
       "14442    ZSARACOM.BO  7/30/2024  23827                  9848.50   8600.00\n",
       "14443    ZSARACOM.BO  8/30/2024  23827                 17125.18   8700.00\n",
       "14444    ZSARACOM.BO  9/23/2024  23827                 26441.24  14047.45\n",
       "\n",
       "[14445 rows x 5 columns]>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merge tables\n",
    "tables = [A, B, C, D, E, F, G, H]\n",
    "final_table = pd.DataFrame()\n",
    "\n",
    "for table in tables:\n",
    "    # Debugging: check the number of rows in each table before melt\n",
    "    print(f\"Table before melt (rows): {len(table)}\")\n",
    "\n",
    "    if 'Ticker' in table.columns:\n",
    "        temp = pd.melt(table, id_vars=['Date/Time', 'Ticker'], var_name='Field', value_name='Value')\n",
    "    else:\n",
    "        temp = pd.melt(table, id_vars=['Date/Time'], var_name='Field', value_name='Value')\n",
    "\n",
    "# Debugging: check the number of rows after melt\n",
    "print(f\"Table after melt (rows): {len(temp)}\")\n",
    "\n",
    "final_table = pd.concat([final_table, temp], ignore_index=True)\n",
    "\n",
    "# Pivot the table to the final structure\n",
    "final_table = final_table.pivot_table(index=['Date/Time', 'Ticker'], columns='Field', values='Value', aggfunc='first').reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of              Ticker  Date/Time    Close       hh       ll  FromLow  FromHigh\n",
       "0         1STCUS.BO  9/20/2024   113.95   127.19    89.35      1.0       0.0\n",
       "1         1STCUS.BO  9/27/2024   121.55   126.35    89.35      2.0       0.0\n",
       "2     21STCENMGM.NS  9/20/2024   120.82   141.40    42.70      0.0       1.0\n",
       "3     21STCENMGM.NS  9/27/2024   109.19   141.40   109.19      0.0       2.0\n",
       "4      20MICRONS.NS  9/20/2024   301.65   348.00   285.40      0.0       4.0\n",
       "...             ...        ...      ...      ...      ...      ...       ...\n",
       "6869   ZYDUSLIFE.NS  9/27/2024  1075.95  1324.30  1038.55      0.0       0.0\n",
       "6870   ZYDUSWELL.NS  9/20/2024  2080.65  2484.00  2055.50      0.0       0.0\n",
       "6871   ZYDUSWELL.NS  9/27/2024  2013.00  2484.00  1961.25      0.0       0.0\n",
       "6872   ZODJRDMKJ.BO  9/20/2024    89.60   134.99    86.95      0.0       3.0\n",
       "6873   ZODJRDMKJ.BO  9/27/2024    90.00   134.99    85.75      0.0       0.0\n",
       "\n",
       "[6874 rows x 7 columns]>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Debugging: check if any rows are dropped after the pivot\n",
    "    print(f\"Final table after pivot (rows): {len(final_table)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Wedge', 'Up Channel', 'Down Channel', 'Broadening Wedge',\n",
       "       'Ascending Triangle', 'Decending Triangle', nan], dtype=object)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.rename(columns={'BullBreak': 'Buy_BB'}, inplace=True)\n",
    "F['Buy_BB'] = F['Buy_BB'].replace('bullish Breakout', 'BB')\n",
    "F['Pattern'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the function to change the values \n",
    "def change_status(value):\n",
    "    if value =='Wedge':\n",
    "        return 'W'\n",
    "    elif value == 'Up Channel':\n",
    "        return 'UC'\n",
    "    elif value == 'Down Channel':\n",
    "        return 'DC'\n",
    "    elif value == 'Broadening Wedge':\n",
    "        return 'BW'\n",
    "    elif value == 'Ascending Triangle':\n",
    "        return 'AT'\n",
    "    elif value == 'Decending Triangle':\n",
    "        return 'DT'\n",
    "    else:\n",
    "        return value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['W', 'UC', 'DC', 'BW', 'AT', 'DT', nan], dtype=object)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Apply the function on pattern from dataset F\n",
    "F['Pattern'] = F['Pattern'].apply(change_status)\n",
    "F['Pattern'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['ZZ'], dtype=object)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "H.rename(columns={'Buy':'Buy_ZZ'}, inplace=True)\n",
    "H['Buy_ZZ'] = H['Buy_ZZ'].replace(1, 'ZZ')\n",
    "H['Buy_ZZ'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of dataframes to merge\n",
    "tables = [A, B, C, D, E, F, G, H]\n",
    "\n",
    "# Start with an empty DataFrame for the final result\n",
    "final_table = pd.DataFrame()\n",
    "\n",
    "# Perform full outer join on Date/Time and create new rows for each Ticker\n",
    "for table in tables:\n",
    "    if 'Ticker' in table.columns:\n",
    "        # Include 'Ticker' and 'Date/Time' in the melt operation\n",
    "        temp = pd.melt(table, id_vars=['Date/Time', 'Ticker'], var_name='Field', value_name='Value')\n",
    "    else:\n",
    "        # If 'Ticker' is not present, use only 'Date/Time'\n",
    "        temp = pd.melt(table, id_vars=['Date/Time'], var_name='Field', value_name='Value')\n",
    "\n",
    "    final_table = pd.concat([final_table, temp], ignore_index=True)\n",
    "\n",
    "# Pivot the final table to get back the desired structure\n",
    "final_table = final_table.pivot_table(index=['Date/Time', 'Ticker'], columns='Field', values='Value', aggfunc='first').reset_index()\n",
    "\n",
    "# Re-arrange columns to have 'Ticker' as the first column\n",
    "cols = ['Ticker', 'Date/Time'] + [col for col in final_table.columns if col not in ['Ticker', 'Date/Time']]\n",
    "final_table = final_table[cols]\n",
    "\n",
    "# Fill NaN values with empty strings for the relevant columns\n",
    "final_table[['Buy_ATR', 'Buy_EW', 'Buy_BB', 'Buy_LR', 'Pattern']] = final_table[['Buy_ATR', 'Buy_EW', 'Buy_BB', 'Buy_LR', 'Pattern']].fillna('')\n",
    "\n",
    "# Create the 'Buy' column by concatenating the values from relevant columns\n",
    "final_table['Buy'] = final_table['Buy_ATR'].astype(str) + final_table['Buy_EW'].astype(str) + final_table['Buy_BB'].astype(str) + final_table['Buy_LR'].astype(str) + final_table['Pattern'].astype(str)\n",
    "\n",
    "# Re-arrange columns to place 'Buy' in the desired order\n",
    "cols = ['Ticker', 'Date/Time', 'Buy'] + [col for col in final_table.columns if col not in ['Ticker', 'Date/Time', 'Buy']]\n",
    "final_table = final_table[cols]\n",
    "\n",
    "# Save the result to a CSV file\n",
    "final_table.to_csv('joined_tickers.csv', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
